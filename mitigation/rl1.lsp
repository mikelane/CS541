;; simple RL example from the Tom Mitchell Book - ch 13
;; Q Learning for deterministic Markov process
;; reward function is bounded and deterministic
;; actions are deterministic
;; every stae-action pair is visited infinitely often
;;
(defvar gamma 0.9)
(defvar no-of-states 6)
(defvar no-of-actions 4)
(defvar actions '(move-east move-west  move-north move-south))
(defvar states '(s1 s2 s3 s4 s5 s6))
(defvar absorbing-goal-states '(s3))
(defvar non-goal-states '(s1 s2 s4 s5 s6))
(defvar no-sa-pairs 12)
(defvar qhat nil)
(defvar chg nil)

(defvar state-action-table '(((s1 move-east) s2) ((s1 move-south) s4)
                       ((s2 move-west) s1) ((s2 move-south) s5)
                       ((s2 move-east) s3) ((s4 move-north) s1)
                       ((s4 move-east) s5) ((s5 move-west) s4)
                       ((s5 move-north) s2) ((s5 move-east) s6)
                       ((s6 move-west) s5) ((s6 move-north) s3)
                       ))
(defvar reward-table '(((s1 move-east) 0) ((s1 move-south) 0)
                       ((s2 move-west) 0) ((s2 move-south) 0)
                       ((s2 move-east) 100) ((s4 move-north) 0)
                       ((s4 move-east) 0) ((s5 move-west) 0)
                       ((s5 move-north) 0) ((s5 move-east) 0)
                       ((s6 move-west) 0) ((s6 move-north) 100)
                       ))

(defun get-next-state (s a)
  (let ((ns nil))
    (dolist (sat state-action-table)
      (if (equal (list s a) (first sat)) (setf ns (second sat)))
      )
    ns
    ))

(defun get-reward (s a)
  (let ((rew 0))
    (dolist (sat reward-table)
      (if (equal (list s a) (first sat)) (setf rew (second sat))) 
      )
    rew)
  )

(defun get-qhat (s a)
  (let ((qv 0))
    (dolist (sat qhat)
      (if (equal (list s a) (first sat)) (setf qv (second sat))) 
      )
    qv)
  )

(defun init-qhat-zero ()
  (let ((qh nil))
    (dolist (sat state-action-table)
      (setf qh (append qh (list (list (first sat) 0))))
      )
   (setf qhat qh)
))
  
(defun init-qhat-random ()
  (let ((qh nil))
    (dolist (sat state-action-table)
      (setf qh (append qh (list (list (first sat) (random 101)))))
      )
    (setf qhat qh)
))

(defun random-non-goal-state ()
  (let ((n 0) (k 0) (s nil))
    (setf n (length non-goal-states))
    (setf k (random n))
    (setf s (nth k non-goal-states))
    s))

(defun get-all-actions (s)
  (let ((al nil) (s1 nil) (a nil))
    (dolist (x qhat)
      (setf s1 (first (first x)))
      (setf a (second (first x)))
      (if (eq s s1) (setf al (append al (list a))))
      )
    al))

(defun select-action (state)
  (let ((n 0) (al nil) (k 0) (a nil))
    (setf al (get-all-actions state))
    (if (null al) (return-from select-action nil))
    (setf n (length al))
    (setf k (random n))
    (setf a (nth k al))
    a)
  )

(defun maxallq (s)
  (let ((m 0) (sp nil) (v 0))
    (dolist (x qhat)
      (setf sp (first (first x))) ;; get state
      (setf v (second x))         ;; get q value
      (if (and (eq s sp) (> v m)) (setf m v))
      )
    m))

(defun print-qhat ()
  (let ((nd 0) (ed 0) (sd 0) (wd 0))
    (format t "~%")
    (format t "qhat~%")
    (format t "        NORTH      EAST     SOUTH      WEST~%")
    (dolist (s states)
      (setf nd (get-qhat s 'move-north))
      (setf ed (get-qhat s 'move-east))
      (setf sd (get-qhat s 'move-south))
      (setf wd (get-qhat s 'move-west))
      (format t " ~A ~9,1f ~9,1f ~9,1f ~9,1f~%" s nd ed sd wd)
      )
    ))

(defun update-qhat (cs act ns rew)
  (let ((s nil) (a nil) (v nil))
    (dolist (x qhat)
      (setf s (first (first x)))
      (setf a (second (first x)))
      (setf v (second x))
      (if (and (eq s cs) (eq a act)) 
          (setf (second x) (+ rew (* gamma (maxallq ns)))))
      (if (eql v (second x)) (setf chg t))
      )
    ))

(defun run (max-episodes)
  (let ((curr-state nil) (next-state nil) (episode 0)
        (action nil) (reward nil) (step 0))
;;
;; init-qhat before calling run
;;
;; start loop here
    (loop ;; loop 1
     (incf episode)
     (format t "~%episode = ~d~%" episode)
     (print-qhat)
     (setf curr-state (random-non-goal-state))
     (setf step 0)
     (setf chg nil)
       (loop ;;loop 2
             (incf step)
             (format t "~%Episode = ~d Step = ~d curr-state = ~a" episode step curr-state)
             (setf action (select-action curr-state))
             (if (null action) (return nil))
             (setf reward (get-reward curr-state action))
             (setf next-state (get-next-state curr-state action)) 
             (format t "~% curr-state = ~a next-state = ~a action = ~a reward = ~d ~%" curr-state next-state action reward)
             (update-qhat curr-state action next-state reward)
             (print-qhat)
             (setf curr-state next-state)
             (if (member curr-state absorbing-goal-states) (return nil))
        );; end loop 2
       (if (null chg) (return-from run nil))
       (if  (>= episode max-episodes) (return-from run nil))
     );; end loop 1
    )
  )
